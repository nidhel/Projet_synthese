{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786fe2eb",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: #4CAF50;\">Modèles pour la Prédiction des Pannes (Modèle 1)</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "    <li><strong>Réseaux de neurones récurrents (RNN) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Notamment <strong>LSTM</strong> (Long Short-Term Memory) et <strong>GRU</strong> (Gated Recurrent Units), pour capturer les dépendances temporelles.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Temporal Fusion Transformer (TFT) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Un modèle avancé adapté aux séries temporelles multivariées, capable de gérer les variables continues et catégoriques tout en capturant les relations complexes.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Gradient Boosting (XGBoost, LightGBM, CatBoost) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Pour exploiter les relations non linéaires et les interactions entre les variables.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Forêts aléatoires (Random Forest) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Pour une approche robuste et interprétable de la classification.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Support Vector Machines (SVM) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Utile pour des prédictions précises dans des contextes bien définis, mais nécessite un prétraitement rigoureux.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Autoencoders :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Pour détecter les anomalies en apprenant la représentation normale des données.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55cb04",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: #4CAF50;\">Observations sur les Approches Modélisées</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "    <li><strong>Observation Unique :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Chaque ligne du dataset (une observation avec ses features) est traitée séparément.</li>\n",
    "            <li>Le modèle n'a pas de notion de dépendance temporelle entre les observations.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Fenêtre Temporelle (non utilisée dans Random Forest classique) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Les fenêtres temporelles sont couramment utilisées dans des modèles spécifiques aux séries temporelles, comme :</li>\n",
    "            <ul style=\"font-size: 11pt; color: #555;\">\n",
    "                <li><strong>LSTM</strong> / <strong>GRU</strong> (réseaux récurrents).</li>\n",
    "                <li><strong>TFT</strong> (Temporal Fusion Transformer).</li>\n",
    "                <li><strong>ARIMA, SARIMA, Prophet</strong>, etc.</li>\n",
    "            </ul>\n",
    "            <li>Dans ce cas, les observations environnantes sont prises en compte pour capturer les relations temporelles.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4210acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fed14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv(\"../Datasources/MetroPT3_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d283704",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>################################################################################################</strong>    \n",
    "<strong>###############################  DÉCLARATION / INITIALISATION  ###############################</strong>\n",
    "<strong>################################################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8f748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "#display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c12577",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d4585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conserver uniquement les colonnes continues, catégorielles et 'timestamp'\n",
    "columns_to_keep = [\"timestamp\", \"panne\"] + continuous_features + categorical_features\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec2a17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>panne</th>\n",
       "      <th>TP2</th>\n",
       "      <th>DV_pressure</th>\n",
       "      <th>Oil_temperature</th>\n",
       "      <th>Motor_current</th>\n",
       "      <th>Reservoirs</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DV_eletric</th>\n",
       "      <th>Towers</th>\n",
       "      <th>LPS</th>\n",
       "      <th>Pressure_switch</th>\n",
       "      <th>Oil_level</th>\n",
       "      <th>Caudal_impulses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.675</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01 00:00:20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>9.338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01 00:00:30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.425</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01 00:00:40</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.475</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841755</th>\n",
       "      <td>2020-09-01 03:59:10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.675</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>8.918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841756</th>\n",
       "      <td>2020-09-01 03:59:20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>59.600</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>8.904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841757</th>\n",
       "      <td>2020-09-01 03:59:30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.600</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>8.892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841758</th>\n",
       "      <td>2020-09-01 03:59:40</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.550</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>8.878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841759</th>\n",
       "      <td>2020-09-01 03:59:50</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.475</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>8.864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841760 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  panne    TP2  DV_pressure  Oil_temperature  \\\n",
       "0       2020-02-01 00:00:00      0 -0.012       -0.024           53.600   \n",
       "1       2020-02-01 00:00:10      0 -0.014       -0.022           53.675   \n",
       "2       2020-02-01 00:00:20      0 -0.012       -0.022           53.600   \n",
       "3       2020-02-01 00:00:30      0 -0.012       -0.022           53.425   \n",
       "4       2020-02-01 00:00:40      0 -0.012       -0.022           53.475   \n",
       "...                     ...    ...    ...          ...              ...   \n",
       "1841755 2020-09-01 03:59:10      0 -0.014       -0.022           59.675   \n",
       "1841756 2020-09-01 03:59:20      0 -0.014       -0.020           59.600   \n",
       "1841757 2020-09-01 03:59:30      0 -0.014       -0.022           59.600   \n",
       "1841758 2020-09-01 03:59:40      0 -0.012       -0.022           59.550   \n",
       "1841759 2020-09-01 03:59:50      0 -0.014       -0.022           59.475   \n",
       "\n",
       "         Motor_current  Reservoirs  COMP  DV_eletric  Towers  LPS  \\\n",
       "0               0.0400       9.358   1.0         0.0     1.0  0.0   \n",
       "1               0.0400       9.348   1.0         0.0     1.0  0.0   \n",
       "2               0.0425       9.338   1.0         0.0     1.0  0.0   \n",
       "3               0.0400       9.328   1.0         0.0     1.0  0.0   \n",
       "4               0.0400       9.318   1.0         0.0     1.0  0.0   \n",
       "...                ...         ...   ...         ...     ...  ...   \n",
       "1841755         0.0425       8.918   1.0         0.0     1.0  0.0   \n",
       "1841756         0.0450       8.904   1.0         0.0     1.0  0.0   \n",
       "1841757         0.0425       8.892   1.0         0.0     1.0  0.0   \n",
       "1841758         0.0450       8.878   1.0         0.0     1.0  0.0   \n",
       "1841759         0.0425       8.864   1.0         0.0     1.0  0.0   \n",
       "\n",
       "         Pressure_switch  Oil_level  Caudal_impulses  \n",
       "0                    1.0        1.0              1.0  \n",
       "1                    1.0        1.0              1.0  \n",
       "2                    1.0        1.0              1.0  \n",
       "3                    1.0        1.0              1.0  \n",
       "4                    1.0        1.0              1.0  \n",
       "...                  ...        ...              ...  \n",
       "1841755              1.0        1.0              1.0  \n",
       "1841756              1.0        1.0              1.0  \n",
       "1841757              1.0        1.0              1.0  \n",
       "1841758              1.0        1.0              1.0  \n",
       "1841759              1.0        1.0              1.0  \n",
       "\n",
       "[1841760 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ced8f6",
   "metadata": {},
   "source": [
    "\n",
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>################################################################################################</strong>    \n",
    "<strong>######################################  FIN DÉCLARATION  ######################################</strong>\n",
    "<strong>################################################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les colonnes sans \"_is_missing\"\n",
    "columns_without_is_missing = [col for col in df.columns if not col.endswith('_is_missing')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a939d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes marquant les valeurs manquantes (is_missing)\n",
    "cols_is_missing = [col + '_is_missing' for col in ['TP2', 'TP3', 'H1', 'DV_pressure', 'Reservoirs', \n",
    "                                                   'Oil_temperature', 'Motor_current', 'COMP', 'DV_eletric', \n",
    "                                                   'Towers', 'MPG', 'LPS', 'Pressure_switch', 'Oil_level', \n",
    "                                                   'Caudal_impulses']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes catégoriques en type category\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af887ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives globales (exclure les colonnes `_is_missing`)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Statistiques descriptives globales\n",
    "print(\"Statistiques descriptives :\")\n",
    "display(df[columns_without_is_missing].describe())\n",
    "\n",
    "# Statistiques pour les colonnes spécifiques (exclure les colonnes `_is_missing`)\n",
    "# Statistiques pour les colonnes spécifiques\n",
    "print(\"\\nNombre de valeurs manquantes par colonne :\")\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percent = (df.isnull().mean() * 100).map(\"{:,.2f}%\".format)\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Valeurs manquantes': missing_counts.map(\"{:,}\".format),\n",
    "    'Pourcentage manquant': missing_percent\n",
    "})\n",
    "\n",
    "# Afficher les statistiques\n",
    "display(missing_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0309efd",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:blue;\">\n",
    "<strong>MODELES DE SERIES TEMPORELLES : LSTM  (LONG SHORT-TERM MEMORY))</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8e5ac",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>########################################################################</strong>    \n",
    "<strong>################################ TEST 1  ################################</strong>\n",
    "<strong>########################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "97992626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs',\n",
       "       'COMP', 'DV_eletric', 'Towers', 'LPS', 'Pressure_switch', 'Oil_level',\n",
       "       'Caudal_impulses'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période Train 1 : 127 days, 14:30:00\n",
      "Période Test  1 : 85 days, 13:29:40\n",
      "---------------------------------\n",
      "Distribution des modalités dans y_train :\n",
      "Modalité 0 : 1072354 observations\n",
      "Modalité 1 : 29877 observations\n",
      "Modalité 2 : 270 observations\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne1 & Panne2 & Panne3  ################\n",
    "################ Test  : Panne4           #########################\n",
    "###################################################################\n",
    "\n",
    "\n",
    "# Colonnes continues et catégoriques\n",
    "continuous_features  = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]\n",
    "target = \"panne\"\n",
    "\n",
    "# Normaliser les colonnes continues\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "# Définir les périodes d'entraînement et de test\n",
    "train_periods = [{'start': '2020-02-01 00:00:00', 'end': '2020-06-07 14:30:00'}]\n",
    "test_periods  = [{'start': '2020-06-07 14:30:10', 'end': '2020-09-01 03:59:50'}]\n",
    "\n",
    "# Définir les indices pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train   = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df[(df['timestamp'] >= start_train) & (df['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Définir les indices pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test   = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df[(df['timestamp'] >= start_test) & (df['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Préparation des ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices].drop(columns=['timestamp', 'panne']).values\n",
    "y_train = df.loc[train_indices, 'panne'].values\n",
    "\n",
    "X_test = df.loc[test_indices].drop(columns=['timestamp', 'panne']).values\n",
    "y_test = df.loc[test_indices, 'panne'].values\n",
    "\n",
    "# Fonction pour créer des séquences\n",
    "def create_sequences(X, y, sequence_length=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:i + sequence_length])\n",
    "        y_seq.append(y[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Séquences pour l'ensemble d'entraînement et de test\n",
    "sequence_length = 30\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
    "\n",
    "\n",
    "###################### Resumé du dataset ###########################\n",
    "display(df.loc[train_indices].drop(columns=['timestamp', 'panne']).columns)\n",
    "\n",
    "# Calculer et afficher les durées\n",
    "for i, period in enumerate(train_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Train {i} : {duration}\")\n",
    "\n",
    "for i, period in enumerate(test_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Test  {i} : {duration}\")    \n",
    "print(\"---------------------------------\")    \n",
    "# Distribution des modalités\n",
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribution des modalités dans y_train :\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Modalité {value} : {count} observations\")\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c62677e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 51ms/step - accuracy: 0.9732 - loss: 0.0558 - val_accuracy: 0.9977 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 50ms/step - accuracy: 0.9783 - loss: 0.0456 - val_accuracy: 0.9968 - val_loss: 0.0220\n",
      "Epoch 3/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 50ms/step - accuracy: 0.9832 - loss: 0.0397 - val_accuracy: 0.9977 - val_loss: 0.0111\n",
      "Epoch 4/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 50ms/step - accuracy: 0.9836 - loss: 0.0386 - val_accuracy: 0.9970 - val_loss: 0.0230\n",
      "Epoch 5/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 49ms/step - accuracy: 0.9875 - loss: 0.0334 - val_accuracy: 0.9972 - val_loss: 0.0200\n",
      "Epoch 6/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 49ms/step - accuracy: 0.9845 - loss: 0.0372 - val_accuracy: 0.9979 - val_loss: 0.0143\n",
      "Epoch 7/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m851s\u001b[0m 49ms/step - accuracy: 0.9898 - loss: 0.0309 - val_accuracy: 0.9974 - val_loss: 0.0405\n",
      "Epoch 8/50\n",
      "\u001b[1m17227/17227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m854s\u001b[0m 50ms/step - accuracy: 0.9916 - loss: 0.0275 - val_accuracy: 0.9974 - val_loss: 0.0289\n",
      "\u001b[1m23101/23101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0137\n",
      "Test Loss: 0.011118118651211262, Test Accuracy: 0.997685432434082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=lstm_panne_saved_model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Sauvegarde du modèle\u001b[39;00m\n\u001b[0;32m     85\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_panne_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlstm_panne_saved_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModèle LSTM entraîné et sauvegardé avec succès.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:106\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m     legacy_h5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[0;32m    103\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filepath extension for saving. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease add either a `.keras` extension for the native Keras \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat (recommended) or a `.h5` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.export(filepath)` if you want to export a SavedModel \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor use with TFLite/TFServing/etc. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=lstm_panne_saved_model."
     ]
    }
   ],
   "source": [
    "# Construction du modèle LSTM\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 3 classes : 0 (Pas de panne), 1 (En panne), 2 (Avertissement)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Surveiller la perte de validation\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant d'arrêter\n",
    "    restore_best_weights=True # Restaurer les poids de la meilleure époque\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec arrêt anticipé\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"lstm_panne_model_1.h5\")\n",
    "model.save(\"lstm_panne_model_1.keras\")\n",
    "\n",
    "print(\"Modèle LSTM entraîné et sauvegardé avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e69c1bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23101/23101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 11ms/step\n",
      "[[737518      0      0]\n",
      " [  1621      0      0]\n",
      " [    90      0      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    737518\n",
      "           1       0.00      0.00      0.00      1621\n",
      "           2       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           1.00    739229\n",
      "   macro avg       0.33      0.33      0.33    739229\n",
      "weighted avg       1.00      1.00      1.00    739229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(classification_report(y_test_seq, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f126a96",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>########################################################################</strong>    \n",
    "<strong>################################ TEST 2  ################################</strong>\n",
    "<strong>########################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2bc447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs',\n",
       "       'COMP', 'DV_eletric', 'Towers', 'LPS', 'Pressure_switch', 'Oil_level',\n",
       "       'Caudal_impulses'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période Train 1 : 8:30:00\n",
      "Période Test  1 : 2 days, 13:30:00\n",
      "---------------------------------\n",
      "Distribution des modalités dans y_train :\n",
      "Modalité 0 : 630 observations\n",
      "Modalité 1 : 2341 observations\n",
      "Modalité 2 : 90 observations\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne2                    ################\n",
    "################ Test  : Panne3           #########################\n",
    "###################################################################\n",
    "\n",
    "\n",
    "# Colonnes continues et catégoriques\n",
    "continuous_features  = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]\n",
    "target = \"panne\"\n",
    "\n",
    "# Normaliser les colonnes continues\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "# Définir les périodes d'entraînement et de test\n",
    "train_periods = [{'start': '2020-05-29 22:30:00', 'end': '2020-05-30 07:00:00'}]\n",
    "test_periods = [{'start': '2020-06-05 06:00:00', 'end': '2020-06-07 19:30:00'}]\n",
    "\n",
    "# Définir les indices pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df[(df['timestamp'] >= start_train) & (df['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Définir les indices pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test   = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df[(df['timestamp'] >= start_test) & (df['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Préparation des ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices].drop(columns=['timestamp', 'panne']).values\n",
    "y_train = df.loc[train_indices, 'panne'].values\n",
    "\n",
    "X_test = df.loc[test_indices].drop(columns=['timestamp', 'panne']).values\n",
    "y_test = df.loc[test_indices, 'panne'].values\n",
    "\n",
    "# Fonction pour créer des séquences\n",
    "def create_sequences(X, y, sequence_length=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:i + sequence_length])\n",
    "        y_seq.append(y[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Séquences pour l'ensemble d'entraînement et de test\n",
    "sequence_length = 30\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
    "\n",
    "###################### Resumé du dataset ###########################\n",
    "display(df.loc[train_indices].drop(columns=['timestamp', 'panne']).columns)\n",
    "\n",
    "# Calculer et afficher les durées\n",
    "for i, period in enumerate(train_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Train {i} : {duration}\")\n",
    "\n",
    "for i, period in enumerate(test_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Test  {i} : {duration}\")    \n",
    "print(\"---------------------------------\")    \n",
    "# Distribution des modalités\n",
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribution des modalités dans y_train :\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Modalité {value} : {count} observations\")\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceaa53c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 171ms/step - accuracy: 0.8193 - loss: 0.4521 - val_accuracy: 0.2404 - val_loss: 1.8353\n",
      "Epoch 2/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - accuracy: 0.8981 - loss: 0.3383 - val_accuracy: 0.9070 - val_loss: 0.3131\n",
      "Epoch 3/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - accuracy: 0.9575 - loss: 0.1836 - val_accuracy: 0.9141 - val_loss: 0.3504\n",
      "Epoch 4/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - accuracy: 0.9608 - loss: 0.1626 - val_accuracy: 0.9142 - val_loss: 0.4825\n",
      "Epoch 5/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - accuracy: 0.9620 - loss: 0.1556 - val_accuracy: 0.9143 - val_loss: 0.4958\n",
      "Epoch 6/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.9644 - loss: 0.1439 - val_accuracy: 0.9144 - val_loss: 0.5176\n",
      "Epoch 7/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - accuracy: 0.9651 - loss: 0.1416 - val_accuracy: 0.9143 - val_loss: 0.5566\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9563 - loss: 0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.31308713555336, Test Accuracy: 0.9070146083831787\n",
      "Modèle LSTM entraîné et sauvegardé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Construction du modèle LSTM\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 3 classes : 0 (Pas de panne), 1 (En panne), 2 (Avertissement)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Surveiller la perte de validation\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant d'arrêter\n",
    "    restore_best_weights=True # Restaurer les poids de la meilleure époque\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec arrêt anticipé\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"lstm_panne_model_2.h5\")\n",
    "model.save(\"lstm_panne_model_2.keras\")\n",
    "\n",
    "print(\"Modèle LSTM entraîné et sauvegardé avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "292cf3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step\n",
      "[[ 1154  1966     0]\n",
      " [    0 18901     0]\n",
      " [   43    47     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.37      0.53      3120\n",
      "           1       0.90      1.00      0.95     18901\n",
      "           2       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.91     22111\n",
      "   macro avg       0.62      0.46      0.49     22111\n",
      "weighted avg       0.91      0.91      0.89     22111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(classification_report(y_test_seq, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b749e",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>########################################################################</strong>    \n",
    "<strong>################################ TEST 3  ################################</strong>\n",
    "<strong>########################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2f7d2a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs',\n",
       "       'COMP', 'DV_eletric', 'Towers', 'LPS', 'Pressure_switch', 'Oil_level',\n",
       "       'Caudal_impulses'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période Train 1 : 135 days, 4:00:40\n",
      "Période Test  1 : 77 days, 23:59:00\n",
      "---------------------------------\n",
      "Distribution des modalités dans y_train :\n",
      "Modalité 0 : 1144712 observations\n",
      "Modalité 1 : 22863 observations\n",
      "Modalité 2 : 270 observations\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne2 & Panne3 & Panne4   ################\n",
    "################ Test  : Panne1           #########################\n",
    "###################################################################\n",
    "\n",
    "# Colonnes continues et catégoriques\n",
    "continuous_features = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]\n",
    "target = \"panne\"\n",
    "\n",
    "# Normaliser les colonnes continues\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "# Définir les périodes d'entraînement et de test\n",
    "train_periods = [{'start': '2020-04-18 23:59:10', 'end': '2020-09-01 03:59:50'}]\n",
    "test_periods  = [{'start': '2020-02-01 00:00:00', 'end': '2020-04-18 23:59:00'}]\n",
    "\n",
    "# Définir les indices pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train   = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df[(df['timestamp'] >= start_train) & (df['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Définir les indices pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test   = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df[(df['timestamp'] >= start_test) & (df['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Préparation des ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices].drop(columns=['timestamp', 'panne']).values\n",
    "y_train = df.loc[train_indices, 'panne'].values\n",
    "\n",
    "X_test = df.loc[test_indices].drop(columns=['timestamp', 'panne']).values\n",
    "y_test = df.loc[test_indices, 'panne'].values\n",
    "\n",
    "# Fonction pour créer des séquences\n",
    "def create_sequences(X, y, sequence_length=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:i + sequence_length])\n",
    "        y_seq.append(y[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Séquences pour l'ensemble d'entraînement et de test\n",
    "sequence_length = 30\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
    "\n",
    "\n",
    "###################### Resumé du dataset ###########################\n",
    "display(df.loc[train_indices].drop(columns=['timestamp', 'panne']).columns)\n",
    "\n",
    "# Calculer et afficher les durées\n",
    "for i, period in enumerate(train_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Train {i} : {duration}\")\n",
    "\n",
    "for i, period in enumerate(test_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Test  {i} : {duration}\")    \n",
    "print(\"---------------------------------\")    \n",
    "# Distribution des modalités\n",
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribution des modalités dans y_train :\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Modalité {value} : {count} observations\")\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6732c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2536s\u001b[0m 139ms/step - accuracy: 0.9799 - loss: 0.1878 - val_accuracy: 0.9871 - val_loss: 0.0709\n",
      "Epoch 2/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2565s\u001b[0m 141ms/step - accuracy: 0.9802 - loss: 0.0987 - val_accuracy: 0.9871 - val_loss: 0.0707\n",
      "Epoch 3/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2584s\u001b[0m 142ms/step - accuracy: 0.9804 - loss: 0.0979 - val_accuracy: 0.9871 - val_loss: 0.0700\n",
      "Epoch 4/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2600s\u001b[0m 142ms/step - accuracy: 0.9803 - loss: 0.0982 - val_accuracy: 0.9871 - val_loss: 0.0704\n",
      "Epoch 5/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2648s\u001b[0m 145ms/step - accuracy: 0.9803 - loss: 0.0983 - val_accuracy: 0.9871 - val_loss: 0.0705\n",
      "Epoch 6/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2672s\u001b[0m 146ms/step - accuracy: 0.9804 - loss: 0.0978 - val_accuracy: 0.9871 - val_loss: 0.0708\n",
      "Epoch 7/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2700s\u001b[0m 148ms/step - accuracy: 0.9801 - loss: 0.0990 - val_accuracy: 0.9871 - val_loss: 0.0718\n",
      "Epoch 8/30\n",
      "\u001b[1m18248/18248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2705s\u001b[0m 148ms/step - accuracy: 0.9800 - loss: 0.0994 - val_accuracy: 0.9871 - val_loss: 0.0712\n",
      "\u001b[1m21059/21059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.07002128660678864, Test Accuracy: 0.9870526790618896\n",
      "Modèle LSTM entraîné et sauvegardé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Construction du modèle LSTM\n",
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=True, kernel_regularizer=l2(0.01), input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(3, activation='softmax')  # 3 classes : 0 (Pas de panne), 1 (En panne), 2 (Avertissement)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Surveiller la perte de validation\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant d'arrêter\n",
    "    restore_best_weights=True # Restaurer les poids de la meilleure époque\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec arrêt anticipé\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"lstm_panne_model_3.h5\")\n",
    "model.save(\"lstm_panne_model_3.keras\")\n",
    "\n",
    "print(\"Modèle LSTM entraîné et sauvegardé avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f38c8ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21059/21059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 29ms/step\n",
      "[[665160      0      0]\n",
      " [  8635      0      0]\n",
      " [    90      0      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    665160\n",
      "           1       0.00      0.00      0.00      8635\n",
      "           2       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.99    673885\n",
      "   macro avg       0.33      0.33      0.33    673885\n",
      "weighted avg       0.97      0.99      0.98    673885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(classification_report(y_test_seq, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238de7b2",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>########################################################################</strong>    \n",
    "<strong>################################ TEST 4  ################################</strong>\n",
    "<strong>########################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30e938b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs',\n",
       "       'COMP', 'DV_eletric', 'Towers'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période Train 1 : 119 days, 6:00:00\n",
      "Période Test  1 : 93 days, 21:59:40\n",
      "---------------------------------\n",
      "Distribution des modalités dans y_train :\n",
      "Modalité 0 : 1019165 observations\n",
      "Modalité 1 : 10976 observations\n",
      "Modalité 2 : 180 observations\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne1 & Panne2           ################\n",
    "################ Test  : Panne3 & Panne4  #########################\n",
    "###################################################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Colonnes continues et catégoriques\n",
    "continuous_features  = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]\n",
    "columns_to_exclude   = ['timestamp', 'panne', 'LPS', 'Pressure_switch', 'Oil_level', 'Caudal_impulses']\n",
    "\n",
    "target = \"panne\"\n",
    "\n",
    "# Normaliser les colonnes continues\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "# Définir les périodes d'entraînement et de test\n",
    "train_periods = [{'start': '2020-02-01 00:00:00', 'end': '2020-05-30 06:00:00'}]\n",
    "test_periods  = [{'start': '2020-05-30 06:00:10', 'end': '2020-09-01 03:59:50'}]\n",
    "\n",
    "# Définir les indices pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df[(df['timestamp'] >= start_train) & (df['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Définir les indices pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df[(df['timestamp'] >= start_test) & (df['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Préparation des ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices].drop(columns=columns_to_exclude).values\n",
    "y_train = df.loc[train_indices, 'panne'].values\n",
    "\n",
    "X_test = df.loc[test_indices].drop(columns=columns_to_exclude).values\n",
    "y_test = df.loc[test_indices, 'panne'].values\n",
    "\n",
    "# Fonction pour créer des séquences\n",
    "def create_sequences(X, y, sequence_length=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:i + sequence_length])\n",
    "        y_seq.append(y[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Séquences pour l'ensemble d'entraînement et de test\n",
    "sequence_length = 30\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
    "\n",
    "###################### Resumé du dataset ###########################\n",
    "display(df.loc[train_indices].drop(columns=columns_to_exclude).columns)\n",
    "\n",
    "# Calculer et afficher les durées\n",
    "for i, period in enumerate(train_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Train {i} : {duration}\")\n",
    "\n",
    "for i, period in enumerate(test_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Test  {i} : {duration}\")    \n",
    "print(\"---------------------------------\")    \n",
    "# Distribution des modalités\n",
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribution des modalités dans y_train :\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Modalité {value} : {count} observations\")\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6283b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 26s/step - accuracy: 0.3952 - loss: 6.4827 - val_accuracy: 0.6528 - val_loss: 5.2700\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 25s/step - accuracy: 0.5375 - loss: 4.6920 - val_accuracy: 0.6547 - val_loss: 3.8072\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 25s/step - accuracy: 0.5163 - loss: 3.4880 - val_accuracy: 0.6716 - val_loss: 2.7213\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 25s/step - accuracy: 0.5148 - loss: 2.6688 - val_accuracy: 0.6097 - val_loss: 2.5478\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 25s/step - accuracy: 0.5362 - loss: 2.1252 - val_accuracy: 0.6346 - val_loss: 2.0081\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 25s/step - accuracy: 0.5477 - loss: 1.7217 - val_accuracy: 0.6157 - val_loss: 1.7918\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 25s/step - accuracy: 0.5717 - loss: 1.4679 - val_accuracy: 0.5965 - val_loss: 1.5473\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 25s/step - accuracy: 0.5932 - loss: 1.3383 - val_accuracy: 0.6419 - val_loss: 1.3908\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 25s/step - accuracy: 0.5678 - loss: 1.2420 - val_accuracy: 0.6206 - val_loss: 1.4203\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.5902 - loss: 1.1520 - val_accuracy: 0.6217 - val_loss: 1.4296\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 25s/step - accuracy: 0.5748 - loss: 1.1223 - val_accuracy: 0.6384 - val_loss: 1.1328\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 25s/step - accuracy: 0.6113 - loss: 1.0383 - val_accuracy: 0.5760 - val_loss: 1.7494\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.5873 - loss: 1.0498 - val_accuracy: 0.6445 - val_loss: 1.1033\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.6078 - loss: 1.0140 - val_accuracy: 0.6274 - val_loss: 1.3233\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.6039 - loss: 0.9791 - val_accuracy: 0.6320 - val_loss: 1.3542\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.5659 - loss: 0.9770 - val_accuracy: 0.6488 - val_loss: 1.2211\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.6241 - loss: 0.9572 - val_accuracy: 0.6358 - val_loss: 1.3512\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.5994 - loss: 0.9468 - val_accuracy: 0.6415 - val_loss: 1.0330\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 25s/step - accuracy: 0.5978 - loss: 0.9227 - val_accuracy: 0.6383 - val_loss: 1.4645\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.5886 - loss: 0.8927 - val_accuracy: 0.6083 - val_loss: 1.4564\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.5902 - loss: 0.9395 - val_accuracy: 0.6240 - val_loss: 1.1118\n",
      "Epoch 22/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 25s/step - accuracy: 0.6093 - loss: 0.9364 - val_accuracy: 0.6146 - val_loss: 1.4172\n",
      "Epoch 23/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 25s/step - accuracy: 0.6138 - loss: 0.9070 - val_accuracy: 0.6009 - val_loss: 1.4677\n",
      "\u001b[1m10859/10859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 36ms/step - accuracy: 0.7025 - loss: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.03300940990448, Test Accuracy: 0.6414580345153809\n",
      "Modèle LSTM entraîné et sauvegardé avec succès.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construction du modèle LSTM\n",
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=True, kernel_regularizer=l2(0.01), input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(3, activation='softmax')  # 3 classes : 0 (Pas de panne), 1 (En panne), 2 (Avertissement)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Surveiller la perte de validation\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant d'arrêter\n",
    "    restore_best_weights=True # Restaurer les poids de la meilleure époque\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec arrêt anticipé\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"lstm_panne_model_4.h5\")\n",
    "model.save(\"lstm_panne_model_4.keras\")\n",
    "\n",
    "print(\"Modèle LSTM entraîné et sauvegardé avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "edae6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10859/10859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 34ms/step\n",
      "[[203716  93774  30739]\n",
      " [     0  19141      0]\n",
      " [    38     28     24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77    328229\n",
      "           1       0.17      1.00      0.29     19141\n",
      "           2       0.00      0.27      0.00        90\n",
      "\n",
      "    accuracy                           0.64    347460\n",
      "   macro avg       0.39      0.63      0.35    347460\n",
      "weighted avg       0.95      0.64      0.74    347460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(classification_report(y_test_seq, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0f69b",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>########################################################################</strong>    \n",
    "<strong>################################ TEST 5  ################################</strong>\n",
    "<strong>########################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c464152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs',\n",
       "       'COMP', 'DV_eletric', 'Towers'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période Train 1 : 0:45:00\n",
      "Période Train 2 : 0:45:00\n",
      "Période Train 3 : 0:45:00\n",
      "Période Test  1 : 0:45:00\n",
      "---------------------------------\n",
      "Distribution des modalités dans y_train :\n",
      "Modalité 0 : 270 observations\n",
      "Modalité 1 : 273 observations\n",
      "Modalité 2 : 270 observations\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "################ Train : Panne1 & Panne2 & Panne3  (15mn + 15mn + 15mn) pour chaque panne   #######\n",
    "################ Test  : Panne4  (15mn + 15mn + 15mn)     #########################################\n",
    "###################################################################################################\n",
    "\n",
    "# Colonnes continues et catégoriques\n",
    "continuous_features = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]\n",
    "columns_to_exclude = ['timestamp', 'panne', 'LPS', 'Pressure_switch', 'Oil_level', 'Caudal_impulses']\n",
    "\n",
    "target = \"panne\"\n",
    "\n",
    "# Normaliser les colonnes continues\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "# Définir les périodes d'entraînement et de test\n",
    "# Définir les périodes d'entraînement et de test\n",
    "train_periods = [\n",
    "    {'start': '2020-04-17 23:30:00', 'end': '2020-04-18 00:15:00'},  # Panne1\n",
    "    {'start': '2020-05-29 23:00:00', 'end': '2020-05-29 23:45:00'},  # Panne2\n",
    "    {'start': '2020-06-05 09:30:00', 'end': '2020-06-05 10:15:00'}   # Panne3\n",
    "                 ]\n",
    "\n",
    "test_periods = [{'start': '2020-07-15 14:00:00', 'end': '2020-07-15 14:45:00'}]  #  Panne4\n",
    "\n",
    "# Définir les indices pour les périodes d'entraînement\n",
    "train_indices = []\n",
    "for period in train_periods:\n",
    "    start_train = pd.Timestamp(period['start'])\n",
    "    end_train = pd.Timestamp(period['end'])\n",
    "    indices = df[(df['timestamp'] >= start_train) & (df['timestamp'] <= end_train)].index.tolist()\n",
    "    train_indices.extend(indices)\n",
    "\n",
    "\n",
    "# Définir les indices pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df[(df['timestamp'] >= start_test) & (df['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Préparation des ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices].drop(columns=columns_to_exclude).values\n",
    "y_train = df.loc[train_indices, 'panne'].values\n",
    "\n",
    "X_test = df.loc[test_indices].drop(columns=columns_to_exclude).values\n",
    "y_test = df.loc[test_indices, 'panne'].values\n",
    "\n",
    "# Fonction pour créer des séquences\n",
    "def create_sequences(X, y, sequence_length=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:i + sequence_length])\n",
    "        y_seq.append(y[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Séquences pour l'ensemble d'entraînement et de test\n",
    "sequence_length = 30\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
    "\n",
    "###################### Resumé du dataset ###########################\n",
    "display(df.loc[train_indices].drop(columns=columns_to_exclude).columns)\n",
    "\n",
    "# Calculer et afficher les durées\n",
    "for i, period in enumerate(train_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Train {i} : {duration}\")\n",
    "\n",
    "for i, period in enumerate(test_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Test  {i} : {duration}\")    \n",
    "print(\"---------------------------------\")    \n",
    "# Distribution des modalités\n",
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribution des modalités dans y_train :\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Modalité {value} : {count} observations\")\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e0d94022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 232ms/step - accuracy: 0.4577 - loss: 6.4586 - val_accuracy: 0.3983 - val_loss: 5.2145\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.5039 - loss: 4.7081 - val_accuracy: 0.4689 - val_loss: 3.8999\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - accuracy: 0.5386 - loss: 3.4944 - val_accuracy: 0.4606 - val_loss: 3.0526\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - accuracy: 0.5394 - loss: 2.6690 - val_accuracy: 0.4523 - val_loss: 2.5122\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - accuracy: 0.5460 - loss: 2.1034 - val_accuracy: 0.4647 - val_loss: 2.1682\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.5598 - loss: 1.7300 - val_accuracy: 0.4730 - val_loss: 1.9119\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - accuracy: 0.5494 - loss: 1.5278 - val_accuracy: 0.4896 - val_loss: 1.6841\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - accuracy: 0.5515 - loss: 1.3491 - val_accuracy: 0.5062 - val_loss: 1.5988\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - accuracy: 0.5296 - loss: 1.2408 - val_accuracy: 0.4855 - val_loss: 1.4685\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - accuracy: 0.5563 - loss: 1.1748 - val_accuracy: 0.5270 - val_loss: 1.5011\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.5817 - loss: 1.0686 - val_accuracy: 0.5187 - val_loss: 1.5176\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - accuracy: 0.5757 - loss: 1.1026 - val_accuracy: 0.5187 - val_loss: 1.3941\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - accuracy: 0.6132 - loss: 1.0137 - val_accuracy: 0.5311 - val_loss: 1.3422\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - accuracy: 0.6045 - loss: 0.9896 - val_accuracy: 0.5436 - val_loss: 1.4715\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - accuracy: 0.5810 - loss: 1.0058 - val_accuracy: 0.5311 - val_loss: 1.3727\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - accuracy: 0.6213 - loss: 0.9517 - val_accuracy: 0.5560 - val_loss: 1.2078\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - accuracy: 0.6229 - loss: 0.9460 - val_accuracy: 0.5477 - val_loss: 1.3581\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.6571 - loss: 0.8688 - val_accuracy: 0.5560 - val_loss: 1.3275\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - accuracy: 0.6437 - loss: 0.8556 - val_accuracy: 0.5560 - val_loss: 1.4442\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - accuracy: 0.5991 - loss: 0.8937 - val_accuracy: 0.5394 - val_loss: 1.3292\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.6374 - loss: 0.8703 - val_accuracy: 0.5353 - val_loss: 1.4409\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3388 - loss: 1.6259\n",
      "Test Loss: 1.2078227996826172, Test Accuracy: 0.5560166239738464\n",
      "Modèle LSTM entraîné et sauvegardé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Construction du modèle LSTM\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])),  # Définir la forme de l'entrée ici\n",
    "    LSTM(256, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(3, activation='softmax')  # 3 classes : 0 (Pas de panne), 1 (En panne), 2 (Avertissement)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Surveiller la perte de validation\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant d'arrêter\n",
    "    restore_best_weights=True # Restaurer les poids de la meilleure époque\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec arrêt anticipé\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"lstm_panne_model_5.keras\")\n",
    "\n",
    "print(\"Modèle LSTM entraîné et sauvegardé avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fb50bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step\n",
      "[[ 7 35 18]\n",
      " [ 0 91  0]\n",
      " [34 20 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.12      0.14        60\n",
      "           1       0.62      1.00      0.77        91\n",
      "           2       0.67      0.40      0.50        90\n",
      "\n",
      "    accuracy                           0.56       241\n",
      "   macro avg       0.49      0.51      0.47       241\n",
      "weighted avg       0.53      0.56      0.51       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(classification_report(y_test_seq, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5e7a0",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>########################################################################</strong>    \n",
    "<strong>################################ TEST 6  ################################</strong>\n",
    "<strong>########################################################################</strong>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cba40a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs',\n",
       "       'COMP', 'DV_eletric', 'Towers'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période Train 1 : 0:45:00\n",
      "Période Train 2 : 0:45:00\n",
      "Période Train 3 : 0:45:00\n",
      "Période Test  1 : 85 days, 13:29:40\n",
      "---------------------------------\n",
      "Distribution des modalités dans y_train :\n",
      "Modalité 0 : 270 observations\n",
      "Modalité 1 : 273 observations\n",
      "Modalité 2 : 270 observations\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "################ Train : Panne1 & Panne2 & Panne3  (15mn + 15mn + 15mn) pour chaque panne   #######\n",
    "################ Test  : Panne4  (all)                    #########################################\n",
    "###################################################################################################\n",
    "\n",
    "# Colonnes continues et catégoriques\n",
    "continuous_features = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]\n",
    "columns_to_exclude = ['timestamp', 'panne', 'LPS', 'Pressure_switch', 'Oil_level', 'Caudal_impulses']\n",
    "\n",
    "target = \"panne\"\n",
    "\n",
    "# Normaliser les colonnes continues\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "# Définir les périodes d'entraînement et de test\n",
    "# Définir les périodes d'entraînement et de test\n",
    "train_periods = [\n",
    "    {'start': '2020-04-17 23:30:00', 'end': '2020-04-18 00:15:00'},  # Panne1\n",
    "    {'start': '2020-05-29 23:00:00', 'end': '2020-05-29 23:45:00'},  # Panne2\n",
    "    {'start': '2020-06-05 09:30:00', 'end': '2020-06-05 10:15:00'}   # Panne3\n",
    "                 ]\n",
    "\n",
    "test_periods = [{'start': '2020-06-07 14:30:10', 'end': '2020-09-01 03:59:50'}]  #  Panne4\n",
    "\n",
    "# Définir les indices pour les périodes d'entraînement\n",
    "train_indices = []\n",
    "for period in train_periods:\n",
    "    start_train = pd.Timestamp(period['start'])\n",
    "    end_train = pd.Timestamp(period['end'])\n",
    "    indices = df[(df['timestamp'] >= start_train) & (df['timestamp'] <= end_train)].index.tolist()\n",
    "    train_indices.extend(indices)\n",
    "\n",
    "\n",
    "# Définir les indices pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df[(df['timestamp'] >= start_test) & (df['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Préparation des ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices].drop(columns=columns_to_exclude).values\n",
    "y_train = df.loc[train_indices, 'panne'].values\n",
    "\n",
    "X_test = df.loc[test_indices].drop(columns=columns_to_exclude).values\n",
    "y_test = df.loc[test_indices, 'panne'].values\n",
    "\n",
    "# Fonction pour créer des séquences\n",
    "def create_sequences(X, y, sequence_length=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:i + sequence_length])\n",
    "        y_seq.append(y[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Séquences pour l'ensemble d'entraînement et de test\n",
    "sequence_length = 30\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
    "\n",
    "###################### Resumé du dataset ###########################\n",
    "display(df.loc[train_indices].drop(columns=columns_to_exclude).columns)\n",
    "\n",
    "# Calculer et afficher les durées\n",
    "for i, period in enumerate(train_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Train {i} : {duration}\")\n",
    "\n",
    "for i, period in enumerate(test_periods, 1):\n",
    "    start_time = datetime.strptime(period['start'], '%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(period['end'], '%Y-%m-%d %H:%M:%S')\n",
    "    duration = end_time - start_time  # Calculer la durée\n",
    "    print(f\"Période Test  {i} : {duration}\")    \n",
    "print(\"---------------------------------\")    \n",
    "# Distribution des modalités\n",
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribution des modalités dans y_train :\")\n",
    "for value, count in zip(values, counts):\n",
    "    print(f\"Modalité {value} : {count} observations\")\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a05cecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 56s/step - accuracy: 0.4368 - loss: 6.4831 - val_accuracy: 0.3313 - val_loss: 5.6249\n",
      "Epoch 2/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 59s/step - accuracy: 0.4873 - loss: 4.7548 - val_accuracy: 0.6584 - val_loss: 3.8265\n",
      "Epoch 3/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m763s\u001b[0m 64s/step - accuracy: 0.5079 - loss: 3.5358 - val_accuracy: 0.6932 - val_loss: 2.7623\n",
      "Epoch 4/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 58s/step - accuracy: 0.5442 - loss: 2.6898 - val_accuracy: 0.6627 - val_loss: 2.2320\n",
      "Epoch 5/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 56s/step - accuracy: 0.5342 - loss: 2.1424 - val_accuracy: 0.6093 - val_loss: 2.0352\n",
      "Epoch 6/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 56s/step - accuracy: 0.5401 - loss: 1.8088 - val_accuracy: 0.6083 - val_loss: 1.8853\n",
      "Epoch 7/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 56s/step - accuracy: 0.5265 - loss: 1.5944 - val_accuracy: 0.6562 - val_loss: 1.4319\n",
      "Epoch 8/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 59s/step - accuracy: 0.5355 - loss: 1.4046 - val_accuracy: 0.6313 - val_loss: 1.5224\n",
      "Epoch 9/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 58s/step - accuracy: 0.5411 - loss: 1.2702 - val_accuracy: 0.6419 - val_loss: 1.3473\n",
      "Epoch 10/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 56s/step - accuracy: 0.5805 - loss: 1.1876 - val_accuracy: 0.6872 - val_loss: 1.1815\n",
      "Epoch 11/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 56s/step - accuracy: 0.5778 - loss: 1.1356 - val_accuracy: 0.6733 - val_loss: 1.2088\n",
      "Epoch 12/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 57s/step - accuracy: 0.5645 - loss: 1.1076 - val_accuracy: 0.6862 - val_loss: 1.1615\n",
      "Epoch 13/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 58s/step - accuracy: 0.5958 - loss: 1.0443 - val_accuracy: 0.6496 - val_loss: 1.2957\n",
      "Epoch 14/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 56s/step - accuracy: 0.5811 - loss: 1.0038 - val_accuracy: 0.6695 - val_loss: 1.0559\n",
      "Epoch 15/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 55s/step - accuracy: 0.5887 - loss: 0.9990 - val_accuracy: 0.6314 - val_loss: 1.4601\n",
      "Epoch 16/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 58s/step - accuracy: 0.5908 - loss: 0.9715 - val_accuracy: 0.6763 - val_loss: 0.9860\n",
      "Epoch 17/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 61s/step - accuracy: 0.6197 - loss: 0.9649 - val_accuracy: 0.6776 - val_loss: 1.1233\n",
      "Epoch 18/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 61s/step - accuracy: 0.6087 - loss: 0.9149 - val_accuracy: 0.6382 - val_loss: 1.3179\n",
      "Epoch 19/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 63s/step - accuracy: 0.6356 - loss: 0.9187 - val_accuracy: 0.6621 - val_loss: 1.0822\n",
      "Epoch 20/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 59s/step - accuracy: 0.6672 - loss: 0.8925 - val_accuracy: 0.6639 - val_loss: 1.0566\n",
      "Epoch 21/30\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 57s/step - accuracy: 0.6333 - loss: 0.8955 - val_accuracy: 0.5979 - val_loss: 1.5291\n",
      "\u001b[1m23101/23101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 35ms/step - accuracy: 0.6357 - loss: 1.0412\n",
      "Test Loss: 0.985927164554596, Test Accuracy: 0.6763222217559814\n",
      "Modèle LSTM entraîné et sauvegardé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Construction du modèle LSTM\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])),  # Définir la forme de l'entrée ici\n",
    "    LSTM(256, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(3, activation='softmax')  # 3 classes : 0 (Pas de panne), 1 (En panne), 2 (Avertissement)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Surveiller la perte de validation\n",
    "    patience=5,            # Nombre d'époques sans amélioration avant d'arrêter\n",
    "    restore_best_weights=True # Restaurer les poids de la meilleure époque\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec arrêt anticipé\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"lstm_panne_model_6.keras\")\n",
    "\n",
    "print(\"Modèle LSTM entraîné et sauvegardé avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a384ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23101/23101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m794s\u001b[0m 34ms/step\n",
      "[[498351 169300  69867]\n",
      " [    38   1583      0]\n",
      " [    39     28     23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81    737518\n",
      "           1       0.01      0.98      0.02      1621\n",
      "           2       0.00      0.26      0.00        90\n",
      "\n",
      "    accuracy                           0.68    739229\n",
      "   macro avg       0.34      0.64      0.28    739229\n",
      "weighted avg       1.00      0.68      0.80    739229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n",
    "print(confusion_matrix(y_test_seq, y_pred))\n",
    "print(classification_report(y_test_seq, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493a116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
