{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786fe2eb",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: #4CAF50;\">Modèles pour la Prédiction des Pannes (Modèle 1)</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "    <li><strong>Réseaux de neurones récurrents (RNN) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Notamment <strong>LSTM</strong> (Long Short-Term Memory) et <strong>GRU</strong> (Gated Recurrent Units), pour capturer les dépendances temporelles.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Temporal Fusion Transformer (TFT) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Un modèle avancé adapté aux séries temporelles multivariées, capable de gérer les variables continues et catégoriques tout en capturant les relations complexes.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Gradient Boosting (XGBoost, LightGBM, CatBoost) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Pour exploiter les relations non linéaires et les interactions entre les variables.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Forêts aléatoires (Random Forest) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Pour une approche robuste et interprétable de la classification.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Support Vector Machines (SVM) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Utile pour des prédictions précises dans des contextes bien définis, mais nécessite un prétraitement rigoureux.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Autoencoders :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Pour détecter les anomalies en apprenant la représentation normale des données.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55cb04",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: #4CAF50;\">Observations sur les Approches Modélisées</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "    <li><strong>Observation Unique :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Chaque ligne du dataset (une observation avec ses features) est traitée séparément.</li>\n",
    "            <li>Le modèle n'a pas de notion de dépendance temporelle entre les observations.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Fenêtre Temporelle (non utilisée dans Random Forest classique) :</strong>\n",
    "        <ul style=\"font-size: 11pt; color: #555;\">\n",
    "            <li>Les fenêtres temporelles sont couramment utilisées dans des modèles spécifiques aux séries temporelles, comme :</li>\n",
    "            <ul style=\"font-size: 11pt; color: #555;\">\n",
    "                <li><strong>LSTM</strong> / <strong>GRU</strong> (réseaux récurrents).</li>\n",
    "                <li><strong>TFT</strong> (Temporal Fusion Transformer).</li>\n",
    "                <li><strong>ARIMA, SARIMA, Prophet</strong>, etc.</li>\n",
    "            </ul>\n",
    "            <li>Dans ce cas, les observations environnantes sont prises en compte pour capturer les relations temporelles.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4210acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fed14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv(\"../Datasources/MetroPT3_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d283704",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: RED;\">################# DÉCLARATION / INITIALISATION #################</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8f748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "#display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c12577",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\", \"LPS\", \"Pressure_switch\", \"Oil_level\", \"Caudal_impulses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d4585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conserver uniquement les colonnes continues, catégorielles et 'timestamp'\n",
    "columns_to_keep = [\"timestamp\", \"panne\"] + continuous_features + categorical_features\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec2a17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>panne</th>\n",
       "      <th>TP2</th>\n",
       "      <th>DV_pressure</th>\n",
       "      <th>Oil_temperature</th>\n",
       "      <th>Motor_current</th>\n",
       "      <th>Reservoirs</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DV_eletric</th>\n",
       "      <th>Towers</th>\n",
       "      <th>LPS</th>\n",
       "      <th>Pressure_switch</th>\n",
       "      <th>Oil_level</th>\n",
       "      <th>Caudal_impulses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.675</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01 00:00:20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>9.338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01 00:00:30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.425</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01 00:00:40</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.475</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841755</th>\n",
       "      <td>2020-09-01 03:59:10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.675</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>8.918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841756</th>\n",
       "      <td>2020-09-01 03:59:20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>59.600</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>8.904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841757</th>\n",
       "      <td>2020-09-01 03:59:30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.600</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>8.892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841758</th>\n",
       "      <td>2020-09-01 03:59:40</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.550</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>8.878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841759</th>\n",
       "      <td>2020-09-01 03:59:50</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>59.475</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>8.864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841760 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  panne    TP2  DV_pressure  Oil_temperature  \\\n",
       "0       2020-02-01 00:00:00      0 -0.012       -0.024           53.600   \n",
       "1       2020-02-01 00:00:10      0 -0.014       -0.022           53.675   \n",
       "2       2020-02-01 00:00:20      0 -0.012       -0.022           53.600   \n",
       "3       2020-02-01 00:00:30      0 -0.012       -0.022           53.425   \n",
       "4       2020-02-01 00:00:40      0 -0.012       -0.022           53.475   \n",
       "...                     ...    ...    ...          ...              ...   \n",
       "1841755 2020-09-01 03:59:10      0 -0.014       -0.022           59.675   \n",
       "1841756 2020-09-01 03:59:20      0 -0.014       -0.020           59.600   \n",
       "1841757 2020-09-01 03:59:30      0 -0.014       -0.022           59.600   \n",
       "1841758 2020-09-01 03:59:40      0 -0.012       -0.022           59.550   \n",
       "1841759 2020-09-01 03:59:50      0 -0.014       -0.022           59.475   \n",
       "\n",
       "         Motor_current  Reservoirs  COMP  DV_eletric  Towers  LPS  \\\n",
       "0               0.0400       9.358   1.0         0.0     1.0  0.0   \n",
       "1               0.0400       9.348   1.0         0.0     1.0  0.0   \n",
       "2               0.0425       9.338   1.0         0.0     1.0  0.0   \n",
       "3               0.0400       9.328   1.0         0.0     1.0  0.0   \n",
       "4               0.0400       9.318   1.0         0.0     1.0  0.0   \n",
       "...                ...         ...   ...         ...     ...  ...   \n",
       "1841755         0.0425       8.918   1.0         0.0     1.0  0.0   \n",
       "1841756         0.0450       8.904   1.0         0.0     1.0  0.0   \n",
       "1841757         0.0425       8.892   1.0         0.0     1.0  0.0   \n",
       "1841758         0.0450       8.878   1.0         0.0     1.0  0.0   \n",
       "1841759         0.0425       8.864   1.0         0.0     1.0  0.0   \n",
       "\n",
       "         Pressure_switch  Oil_level  Caudal_impulses  \n",
       "0                    1.0        1.0              1.0  \n",
       "1                    1.0        1.0              1.0  \n",
       "2                    1.0        1.0              1.0  \n",
       "3                    1.0        1.0              1.0  \n",
       "4                    1.0        1.0              1.0  \n",
       "...                  ...        ...              ...  \n",
       "1841755              1.0        1.0              1.0  \n",
       "1841756              1.0        1.0              1.0  \n",
       "1841757              1.0        1.0              1.0  \n",
       "1841758              1.0        1.0              1.0  \n",
       "1841759              1.0        1.0              1.0  \n",
       "\n",
       "[1841760 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ced8f6",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; font-family: Arial, sans-serif; color: RED;\">#################### FIN DÉCLARATION #################</h3>\n",
    "<ul style=\"font-family: Arial, sans-serif; font-size: 12pt; color: #333;\">\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les colonnes sans \"_is_missing\"\n",
    "columns_without_is_missing = [col for col in df.columns if not col.endswith('_is_missing')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a939d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes marquant les valeurs manquantes (is_missing)\n",
    "cols_is_missing = [col + '_is_missing' for col in ['TP2', 'TP3', 'H1', 'DV_pressure', 'Reservoirs', \n",
    "                                                   'Oil_temperature', 'Motor_current', 'COMP', 'DV_eletric', \n",
    "                                                   'Towers', 'MPG', 'LPS', 'Pressure_switch', 'Oil_level', \n",
    "                                                   'Caudal_impulses']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes catégoriques en type category\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af887ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives globales (exclure les colonnes `_is_missing`)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Statistiques descriptives globales\n",
    "print(\"Statistiques descriptives :\")\n",
    "display(df[columns_without_is_missing].describe())\n",
    "\n",
    "# Statistiques pour les colonnes spécifiques (exclure les colonnes `_is_missing`)\n",
    "# Statistiques pour les colonnes spécifiques\n",
    "print(\"\\nNombre de valeurs manquantes par colonne :\")\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percent = (df.isnull().mean() * 100).map(\"{:,.2f}%\".format)\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Valeurs manquantes': missing_counts.map(\"{:,}\".format),\n",
    "    'Pourcentage manquant': missing_percent\n",
    "})\n",
    "\n",
    "# Afficher les statistiques\n",
    "display(missing_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d100c4",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:blue;\">\n",
    "<strong>MODELE - Random Forest</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc305a7",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:RED;\">\n",
    "<strong>TEST 1 : sans fenetre de prediction mais par observation unique</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e078330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 1111141\n",
      "Taille de l'ensemble de test : 730619\n",
      "Pannes dans l'entraînement : 30957 (2.79%)\n",
      "Pannes dans le test : 1981 (0.27%)\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne1 & Panne2 & Panne3  ################\n",
    "################ Test  : Panne4           #########################\n",
    "###################################################################\n",
    "\n",
    "# Définir les limites pour le train et le test\n",
    "train_start = pd.Timestamp('2020-02-01 00:00:00')\n",
    "train_end   = pd.Timestamp('2020-06-08 14:30:00')\n",
    "test_start  = pd.Timestamp('2020-06-08 14:30:10')  # Observation suivante\n",
    "test_end    = pd.Timestamp('2020-09-01 03:59:50')\n",
    "\n",
    "# Filtrer les indices pour le train et le test\n",
    "train_indices = df[(df['timestamp'] >= train_start) & (df['timestamp'] <= train_end)].index\n",
    "test_indices  = df[(df['timestamp'] >= test_start) & (df['timestamp'] <= test_end)].index\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices, continuous_features + categorical_features]\n",
    "y_train = df.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df.loc[test_indices, continuous_features + categorical_features]\n",
    "y_test = df.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérifications des tailles des ensembles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n",
    "print(f\"Pannes dans l'entraînement : {y_train.sum()} ({y_train.mean():.2%})\")\n",
    "print(f\"Pannes dans le test : {y_test.sum()} ({y_test.mean():.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4eff3711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    728818\n",
      "           1       0.06      0.00      0.00      1621\n",
      "           2       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           1.00    730619\n",
      "   macro avg       0.35      0.33      0.33    730619\n",
      "weighted avg       1.00      1.00      1.00    730619\n",
      "\n",
      "Importance des features :\n",
      "            Feature  Importance\n",
      "1       DV_pressure    0.397753\n",
      "2   Oil_temperature    0.264562\n",
      "4        Reservoirs    0.150677\n",
      "0               TP2    0.106710\n",
      "3     Motor_current    0.060686\n",
      "5              COMP    0.005960\n",
      "6        DV_eletric    0.004122\n",
      "11  Caudal_impulses    0.003123\n",
      "7            Towers    0.002399\n",
      "10        Oil_level    0.002352\n",
      "8               LPS    0.001180\n",
      "9   Pressure_switch    0.000475\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Entraînement du modèle\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352a321",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:RED;\">\n",
    "<strong>TEST 2 : sans fenetre de prediction mais par observation unique</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91feb873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 1030321\n",
      "Taille de l'ensemble de test : 72180\n",
      "Pannes dans l'entraînement : 11696 (1.14%)\n",
      "Pannes dans le test : 19261 (26.68%)\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne1 & Panne2  ################\n",
    "################ Test  : Panne3           #########################\n",
    "###################################################################\n",
    "\n",
    "\n",
    "# Définir les périodes pour le train et le test\n",
    "train_periods = [{'start': '2020-02-01 00:00:00', 'end': '2020-05-30 06:00:00'}]\n",
    "\n",
    "test_periods  = [{'start': '2020-05-30 06:00:10', 'end': '2020-06-07 14:30:00'}]\n",
    "\n",
    "# Filtrer les indices pour le train\n",
    "train_indices = []\n",
    "for period in train_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    train_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Filtrer les indices pour le test\n",
    "test_indices = []\n",
    "for period in test_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    test_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Vérifier qu'il n'y a pas de chevauchement entre train et test\n",
    "assert len(set(train_indices).intersection(set(test_indices))) == 0, \"Les ensembles d'entraînement et de test se chevauchent !\"\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices, continuous_features + categorical_features]\n",
    "y_train = df.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df.loc[test_indices, continuous_features + categorical_features]\n",
    "y_test = df.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérifications des tailles des ensembles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n",
    "print(f\"Pannes dans l'entraînement : {y_train.sum()} ({y_train.mean():.2%})\")\n",
    "print(f\"Pannes dans le test : {y_test.sum()} ({y_test.mean():.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa7ef15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89     53099\n",
      "           1       0.99      0.33      0.49     18901\n",
      "           2       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.82     72180\n",
      "   macro avg       0.60      0.44      0.46     72180\n",
      "weighted avg       0.85      0.82      0.78     72180\n",
      "\n",
      "Importance des features :\n",
      "            Feature  Importance\n",
      "1       DV_pressure    0.337021\n",
      "4        Reservoirs    0.298922\n",
      "2   Oil_temperature    0.151718\n",
      "0               TP2    0.141438\n",
      "3     Motor_current    0.057051\n",
      "5              COMP    0.004082\n",
      "11  Caudal_impulses    0.004000\n",
      "6        DV_eletric    0.002823\n",
      "7            Towers    0.001325\n",
      "10        Oil_level    0.001229\n",
      "9   Pressure_switch    0.000255\n",
      "8               LPS    0.000137\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Entraînement du modèle\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77ade6",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:RED;\">\n",
    "<strong>TEST 3 : sans fenetre de prediction mais par observation unique</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "################ Train : Panne2 & Panne3 & Panne4  ################\n",
    "################ Test  : Panne1           #########################\n",
    "###################################################################\n",
    "\n",
    "\n",
    "# Définir les périodes pour le train et le test\n",
    "train_periods = [{'start': '2020-04-18 23:59:10', 'end': '2020-09-01 03:59:50'}]\n",
    "\n",
    "test_periods  = [{'start': '2020-02-01 00:00:00', 'end': '2020-04-18 23:59:00'}]\n",
    "\n",
    "# Filtrer les indices pour le train\n",
    "train_indices = []\n",
    "for period in train_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    train_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Filtrer les indices pour le test\n",
    "test_indices = []\n",
    "for period in test_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    test_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Vérifier qu'il n'y a pas de chevauchement entre train et test\n",
    "assert len(set(train_indices).intersection(set(test_indices))) == 0, \"Les ensembles d'entraînement et de test se chevauchent !\"\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices, continuous_features + categorical_features]\n",
    "y_train = df.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df.loc[test_indices, continuous_features + categorical_features]\n",
    "y_test = df.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérifications des tailles des ensembles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n",
    "print(f\"Pannes dans l'entraînement : {y_train.sum()} ({y_train.mean():.2%})\")\n",
    "print(f\"Pannes dans le test : {y_test.sum()} ({y_test.mean():.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55181fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    665100\n",
      "           1       0.05      0.02      0.03      8635\n",
      "           2       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.98    673915\n",
      "   macro avg       0.35      0.34      0.34    673915\n",
      "weighted avg       0.97      0.98      0.98    673915\n",
      "\n",
      "Importance des features :\n",
      "            Feature  Importance\n",
      "2   Oil_temperature    0.449541\n",
      "1       DV_pressure    0.275703\n",
      "4        Reservoirs    0.124612\n",
      "3     Motor_current    0.063869\n",
      "0               TP2    0.062224\n",
      "6        DV_eletric    0.008788\n",
      "5              COMP    0.006130\n",
      "8               LPS    0.003335\n",
      "10        Oil_level    0.002498\n",
      "7            Towers    0.001611\n",
      "9   Pressure_switch    0.001148\n",
      "11  Caudal_impulses    0.000542\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Entraînement du modèle\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a95d1d",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:RED;\">\n",
    "<strong>TEST 4 : sans fenetre de prediction mais par observation unique</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00fb3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 713705\n",
      "Taille de l'ensemble de test : 454140\n",
      "Pannes dans l'entraînement : 21962 (3.08%)\n",
      "Pannes dans le test : 1981 (0.44%)\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne2 & Panne3          ################\n",
    "################ Test  : Panne4           #########################\n",
    "###################################################################\n",
    "# Définir les périodes pour le train et le test\n",
    "train_periods = [{'start': '2020-04-18 23:59:10', 'end': '2020-07-10 14:29:50'}]\n",
    "\n",
    "test_periods  = [{'start': '2020-07-10 14:30:00', 'end': '2020-09-01 03:59:50'}]\n",
    "\n",
    "# Filtrer les indices pour le train\n",
    "train_indices = []\n",
    "for period in train_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    train_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Filtrer les indices pour le test\n",
    "test_indices = []\n",
    "for period in test_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    test_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Vérifier qu'il n'y a pas de chevauchement entre train et test\n",
    "assert len(set(train_indices).intersection(set(test_indices))) == 0, \"Les ensembles d'entraînement et de test se chevauchent !\"\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices, continuous_features + categorical_features]\n",
    "y_train = df.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df.loc[test_indices, continuous_features + categorical_features]\n",
    "y_test = df.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérifications des tailles des ensembles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n",
    "print(f\"Pannes dans l'entraînement : {y_train.sum()} ({y_train.mean():.2%})\")\n",
    "print(f\"Pannes dans le test : {y_test.sum()} ({y_test.mean():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4fd62f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    452339\n",
      "           1       0.00      0.00      0.00      1621\n",
      "           2       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           1.00    454140\n",
      "   macro avg       0.33      0.33      0.33    454140\n",
      "weighted avg       0.99      1.00      0.99    454140\n",
      "\n",
      "Importance des features :\n",
      "            Feature  Importance\n",
      "2   Oil_temperature    0.465423\n",
      "1       DV_pressure    0.277837\n",
      "4        Reservoirs    0.109867\n",
      "0               TP2    0.073029\n",
      "3     Motor_current    0.053944\n",
      "5              COMP    0.006074\n",
      "6        DV_eletric    0.005192\n",
      "10        Oil_level    0.002947\n",
      "8               LPS    0.002274\n",
      "11  Caudal_impulses    0.001638\n",
      "7            Towers    0.001565\n",
      "9   Pressure_switch    0.000210\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Entraînement du modèle\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a160c",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:RED;\">\n",
    "<strong>TEST 5 : sans fenetre de prediction mais par observation unique</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022296f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 1074960\n",
      "Taille de l'ensemble de test : 347220\n",
      "Pannes dans l'entraînement : 11696 (1.09%)\n",
      "Pannes dans le test : 19261 (5.55%)\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne1 & Panne2          ################\n",
    "################ Test  : Panne3           #########################\n",
    "###################################################################\n",
    "# Définir les périodes pour le train et le test\n",
    "train_periods = [{'start': '2020-02-01 00:00:00', 'end': '2020-06-04 09:59:50'}]\n",
    "\n",
    "test_periods  = [{'start': '2020-06-04 10:00:00', 'end': '2020-07-14 14:29:50'}]\n",
    "\n",
    "# Filtrer les indices pour le train\n",
    "train_indices = []\n",
    "for period in train_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    train_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Filtrer les indices pour le test\n",
    "test_indices = []\n",
    "for period in test_periods:\n",
    "    start = pd.Timestamp(period['start'])\n",
    "    end = pd.Timestamp(period['end'])\n",
    "    test_indices.extend(df[(df['timestamp'] >= start) & (df['timestamp'] <= end)].index.tolist())\n",
    "\n",
    "# Vérifier qu'il n'y a pas de chevauchement entre train et test\n",
    "assert len(set(train_indices).intersection(set(test_indices))) == 0, \"Les ensembles d'entraînement et de test se chevauchent !\"\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df.loc[train_indices, continuous_features + categorical_features]\n",
    "y_train = df.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df.loc[test_indices, continuous_features + categorical_features]\n",
    "y_test = df.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérifications des tailles des ensembles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n",
    "print(f\"Pannes dans l'entraînement : {y_train.sum()} ({y_train.mean():.2%})\")\n",
    "print(f\"Pannes dans le test : {y_test.sum()} ({y_test.mean():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cc9925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    328139\n",
      "           1       0.99      0.20      0.34     18901\n",
      "           2       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.96    347220\n",
      "   macro avg       0.65      0.40      0.44    347220\n",
      "weighted avg       0.96      0.96      0.94    347220\n",
      "\n",
      "Importance des features :\n",
      "            Feature  Importance\n",
      "1       DV_pressure    0.340700\n",
      "4        Reservoirs    0.305047\n",
      "2   Oil_temperature    0.148733\n",
      "0               TP2    0.132631\n",
      "3     Motor_current    0.057027\n",
      "5              COMP    0.006078\n",
      "11  Caudal_impulses    0.003527\n",
      "6        DV_eletric    0.002979\n",
      "7            Towers    0.001349\n",
      "10        Oil_level    0.001184\n",
      "9   Pressure_switch    0.000664\n",
      "8               LPS    0.000081\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Entraînement du modèle\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdf6e8",
   "metadata": {},
   "source": [
    "<ul style=\"font-family: times, serif; font-size:14pt; color:RED;\">\n",
    "<strong>TEST 6 : FENETRES DE 15 MIN<strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f593934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé\n",
      " 4 pannes X 15(mn) * 6 (Nbr de gap par minute)\n",
      "--------------------------------------\n",
      "Window =  15 mn  ==> 360 Observations\n",
      "Window =  30 mn  ==> 720 Observations\n",
      "Window =  60 mn  ==> 1440 Observations\n",
      "--------------------------------------\n",
      "Modalités de la colonne 'panne' avec leurs occurrences :\n",
      "0    1809902\n",
      "1      31498\n",
      "2        360\n",
      "Name: panne, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "###########  REDEFINIR LA VARIABLE 'PANNE' ###########\n",
    "### PANNE = 0 : PAS DE PANNE               ###########\n",
    "### PANNE = 1 : EN PLEIN PANNE             ###########\n",
    "### PANNE = 2 : 15 MINUTES AVANT LA PANNE  ###########\n",
    "######################################################\n",
    "## CORRECTION ##\n",
    "\n",
    "\n",
    "warning_duration=15                    # Les minutes ou 'PANNE' = 2\n",
    "    \n",
    "## Traitement du dataset en adequation avec le window de 15 mn\n",
    "\n",
    "# Mise à jour de la colonne 'panne' pour refléter les nouveaux critères\n",
    "def update_panne_column(df, periodes_pannes, warning_duration):\n",
    "    df['panne'] = 0  # Initialiser toutes les valeurs à 0\n",
    "\n",
    "    for periode in periodes_pannes:\n",
    "        start_panne = pd.Timestamp(periode['start'])\n",
    "        end_panne = pd.Timestamp(periode['end'])\n",
    "        warning_start = start_panne - pd.Timedelta(minutes=warning_duration)\n",
    "\n",
    "        # Mettre à jour les valeurs de panne : 1 pour les périodes de panne\n",
    "        df.loc[(df['timestamp'] >= start_panne) & (df['timestamp'] <= end_panne), 'panne'] = 1\n",
    "        \n",
    "        # Mettre à jour les valeurs d'avertissement : 2 pour les 15 minutes avant la panne\n",
    "        df.loc[(df['timestamp'] >= warning_start) & (df['timestamp'] < start_panne), 'panne'] = 2\n",
    "\n",
    "    return df\n",
    "\n",
    "# Appliquer la mise à jour\n",
    "periodes_pannes = [\n",
    "    {'start': '2020-04-18 00:00:00', 'end': '2020-04-18 23:59:00'},\n",
    "    {'start': '2020-05-29 23:30:00', 'end': '2020-05-30 06:00:00'},\n",
    "    {'start': '2020-06-05 10:00:00', 'end': '2020-06-07 14:30:00'},\n",
    "    {'start': '2020-07-15 14:30:00', 'end': '2020-07-15 19:00:00'},\n",
    "]\n",
    "\n",
    "df_updated = update_panne_column(df, periodes_pannes, warning_duration)\n",
    "\n",
    "# Vérification des résultats\n",
    "print(\"Terminé\")\n",
    "print(\" 4 pannes X 15(mn) * 6 (Nbr de gap par minute)\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Window =  15 mn  ==> 360 Observations\")\n",
    "print(\"Window =  30 mn  ==> 720 Observations\")\n",
    "print(\"Window =  60 mn  ==> 1440 Observations\")\n",
    "print(\"--------------------------------------\")\n",
    "# Vérifier les modalités et leurs occurrences dans la colonne 'panne'\n",
    "if 'panne' in df.columns:\n",
    "    panne_modalities = df['panne'].value_counts()\n",
    "    print(\"Modalités de la colonne 'panne' avec leurs occurrences :\")\n",
    "    print(panne_modalities)\n",
    "else:\n",
    "    print(\"La colonne 'panne' n'existe pas dans le DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d53eb645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille originale : (1841760, 14)\n",
      "Taille avec fenêtres temporelles : (1841671, 459)\n"
     ]
    }
   ],
   "source": [
    "# DEFINIR LE FENETRAGE\n",
    "\n",
    "## window_size =  15 mn  ==> 90   Observations\n",
    "## window_size =  30 mn  ==> 180  Observations\n",
    "## window_size =  60 mn  ==> 360  Observations\n",
    "\n",
    "window_size = 90 \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "# Masquer les warnings spécifiques aux performances de DataFrame fragmenté\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "# Créer une fenêtre temporelle\n",
    "def create_temporal_window(df_entree, features, window_size):\n",
    "    \"\"\"\n",
    "    Ajoute des lags pour créer une fenêtre temporelle pour les features spécifiées.\n",
    "\n",
    "    Args:\n",
    "    - df : DataFrame original.\n",
    "    - features : Liste des colonnes pour lesquelles créer les lags.\n",
    "    - window_size : Taille de la fenêtre temporelle (nombre d'observations précédentes).\n",
    "    \n",
    "    Returns:\n",
    "    - df_windowed : DataFrame avec les lags ajoutés.\n",
    "    \"\"\"\n",
    "    df_windowed = df_entree.copy()\n",
    "    for lag in range(1, window_size):\n",
    "        for feature in features:\n",
    "            df_windowed[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "    \n",
    "    # Supprimer les lignes affectées par les décalages\n",
    "    df_windowed = df_windowed.iloc[window_size - 1:].reset_index(drop=True)\n",
    "    return df_windowed\n",
    "\n",
    "# Taille de la fenêtre (90 observations)\n",
    "window_size = 90\n",
    "continuous_features = ['TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs']\n",
    "\n",
    "# Appliquer la création de fenêtres temporelles\n",
    "df_windowed = create_temporal_window(df_updated, continuous_features, window_size)\n",
    "\n",
    "# Vérification des dimensions\n",
    "print(f\"Taille originale : {df.shape}\")\n",
    "print(f\"Taille avec fenêtres temporelles : {df_windowed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9160471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer le dataframe corrigé dans un fichier CSV\n",
    "df_windowed.to_csv(\"../Datasources/MetroPT3_corrected_windowed.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df_windowed = pd.read_csv(\"../Datasources/MetroPT3_corrected_windowed.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df_windowed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convertir timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "#display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82f14031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 1030232\n",
      "Taille de l'ensemble de test : 391860\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne1 & Panne2           ################\n",
    "################ Test  : Panne3                   #################\n",
    "###################################################################\n",
    "\n",
    "# Définir les périodes pour le train et le test\n",
    "train_periods = [{'start': '2020-02-01 00:00:00', 'end': '2020-05-30 06:00:00'}]\n",
    "test_periods  = [{'start': '2020-05-30 06:00:10', 'end': '2020-07-14 14:30:00'}]\n",
    "\n",
    "# Affectations pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df_windowed[(df_windowed['timestamp'] >= start_train) & (df_windowed['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Affectations pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df_windowed[(df_windowed['timestamp'] >= start_test) & (df_windowed['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df_windowed.loc[train_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_train = df_windowed.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df_windowed.loc[test_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_test = df_windowed.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérification des tailles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c85377f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98    372869\n",
      "           1       0.85      0.01      0.03     18901\n",
      "           2       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.95    391860\n",
      "   macro avg       0.60      0.34      0.33    391860\n",
      "weighted avg       0.95      0.95      0.93    391860\n",
      "\n",
      "Importance des features :\n",
      "                  Feature  Importance\n",
      "36       Reservoirs_lag_5    0.031776\n",
      "1             DV_pressure    0.017396\n",
      "13      DV_pressure_lag_1    0.017390\n",
      "113    DV_pressure_lag_21    0.017241\n",
      "98     DV_pressure_lag_18    0.017179\n",
      "..                    ...         ...\n",
      "450  Motor_current_lag_88    0.000043\n",
      "205  Motor_current_lag_39    0.000041\n",
      "170  Motor_current_lag_32    0.000040\n",
      "215  Motor_current_lag_41    0.000034\n",
      "8                     LPS    0.000000\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddaa4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 1102412\n",
      "Taille de l'ensemble de test : 739259\n"
     ]
    }
   ],
   "source": [
    "###################################################################\n",
    "################ Train : Panne1 & Panne2 & Panne3  ################\n",
    "################ Test  : Panne4           #########################\n",
    "###################################################################\n",
    "\n",
    "\n",
    "train_periods = [{'start': '2020-02-01 00:00:00','end': '2020-06-07 14:30:00'}]\n",
    "\n",
    "test_periods  = [{'start': '2020-06-07 14:30:10','end': '2020-09-01 03:59:50'}]\n",
    "\n",
    "# Affectations pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df_windowed[(df_windowed['timestamp'] >= start_train) & (df_windowed['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Affectations pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df_windowed[(df_windowed['timestamp'] >= start_test) & (df_windowed['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df_windowed.loc[train_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_train = df_windowed.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df_windowed.loc[test_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_test = df_windowed.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérification des tailles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c1c45be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    737548\n",
      "           1       0.00      0.00      0.00      1621\n",
      "           2       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           1.00    739259\n",
      "   macro avg       0.33      0.33      0.33    739259\n",
      "weighted avg       1.00      1.00      1.00    739259\n",
      "\n",
      "Importance des features :\n",
      "                  Feature  Importance\n",
      "178    DV_pressure_lag_34    0.027924\n",
      "98     DV_pressure_lag_18    0.022352\n",
      "238    DV_pressure_lag_46    0.022314\n",
      "13      DV_pressure_lag_1    0.017224\n",
      "1             DV_pressure    0.017211\n",
      "..                    ...         ...\n",
      "6              DV_eletric    0.000043\n",
      "195  Motor_current_lag_37    0.000041\n",
      "330  Motor_current_lag_64    0.000040\n",
      "262            TP2_lag_51    0.000039\n",
      "260  Motor_current_lag_50    0.000037\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e8f5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 755825\n",
      "Taille de l'ensemble de test : 412020\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "################ Train : Panne2 & Panne3  ################\n",
    "################ Test  : Panne4           ################\n",
    "##########################################################\n",
    "\n",
    "train_periods = [{'start': '2020-04-18 23:59:10','end': '2020-07-15 11:29:50'}]\n",
    "\n",
    "test_periods = [{'start': '2020-07-15 11:30:00','end': '2020-09-01 03:59:50'}]\n",
    "\n",
    "# Affectations pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df_windowed[(df_windowed['timestamp'] >= start_train) & (df_windowed['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Affectations pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df_windowed[(df_windowed['timestamp'] >= start_test) & (df_windowed['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df_windowed.loc[train_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_train = df_windowed.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df_windowed.loc[test_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_test = df_windowed.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérification des tailles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "084731a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    410309\n",
      "           1       0.00      0.00      0.00      1621\n",
      "           2       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           1.00    412020\n",
      "   macro avg       0.33      0.33      0.33    412020\n",
      "weighted avg       0.99      1.00      0.99    412020\n",
      "\n",
      "Importance des features :\n",
      "                    Feature  Importance\n",
      "29    Oil_temperature_lag_4    0.047452\n",
      "44    Oil_temperature_lag_7    0.034737\n",
      "14    Oil_temperature_lag_1    0.027723\n",
      "54    Oil_temperature_lag_9    0.021146\n",
      "69   Oil_temperature_lag_12    0.020536\n",
      "..                      ...         ...\n",
      "10                Oil_level    0.000014\n",
      "147              TP2_lag_28    0.000013\n",
      "6                DV_eletric    0.000005\n",
      "5                      COMP    0.000005\n",
      "7                    Towers    0.000005\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ee8f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 1167845\n",
      "Taille de l'ensemble de test : 673826\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "################ Train : Panne2 & Panne3 & Panne4   ######\n",
    "################ Test  : Panne1           ################\n",
    "##########################################################\n",
    "\n",
    "train_periods = [{'start': '2020-04-18 23:59:10','end': '2020-09-01 03:59:50'}]\n",
    "\n",
    "test_periods  = [{'start': '2020-02-01 00:00:00','end': '2020-04-18 23:59:00'}]\n",
    "\n",
    "# Affectations pour les périodes d'entraînement\n",
    "start_train = pd.Timestamp(train_periods[0]['start'])\n",
    "end_train = pd.Timestamp(train_periods[0]['end'])\n",
    "train_indices = df_windowed[(df_windowed['timestamp'] >= start_train) & (df_windowed['timestamp'] <= end_train)].index.tolist()\n",
    "\n",
    "# Affectations pour les périodes de test\n",
    "start_test = pd.Timestamp(test_periods[0]['start'])\n",
    "end_test = pd.Timestamp(test_periods[0]['end'])\n",
    "test_indices = df_windowed[(df_windowed['timestamp'] >= start_test) & (df_windowed['timestamp'] <= end_test)].index.tolist()\n",
    "\n",
    "# Créer les ensembles d'entraînement et de test\n",
    "X_train = df_windowed.loc[train_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_train = df_windowed.loc[train_indices, 'panne']\n",
    "\n",
    "X_test = df_windowed.loc[test_indices].drop(columns=['timestamp', 'panne'])\n",
    "y_test = df_windowed.loc[test_indices, 'panne']\n",
    "\n",
    "# Vérification des tailles\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff26ab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    665101\n",
      "           1       0.46      0.27      0.34      8635\n",
      "           2       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.99    673826\n",
      "   macro avg       0.48      0.42      0.45    673826\n",
      "weighted avg       0.98      0.99      0.98    673826\n",
      "\n",
      "Importance des features :\n",
      "                    Feature  Importance\n",
      "29    Oil_temperature_lag_4    0.032554\n",
      "179  Oil_temperature_lag_34    0.025332\n",
      "44    Oil_temperature_lag_7    0.023352\n",
      "14    Oil_temperature_lag_1    0.021492\n",
      "54    Oil_temperature_lag_9    0.020326\n",
      "..                      ...         ...\n",
      "307              TP2_lag_60    0.000021\n",
      "6                DV_eletric    0.000016\n",
      "352              TP2_lag_69    0.000016\n",
      "5                      COMP    0.000010\n",
      "9           Pressure_switch    0.000008\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importance des features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Importance des features :\")\n",
    "print(feature_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
