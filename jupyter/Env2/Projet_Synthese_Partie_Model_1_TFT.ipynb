{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1722a780-503f-4495-a60a-66ad4fc33f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Scripts\\python.exe\n",
      "C:\\Users\\usermine\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "C:\\Users\\usermine\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee6932e-169a-4b45-8d37-3c3aec965eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357e110a-22c3-4371-bd46-8777d7b42c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6589ed0e-b677-44ae-a1cd-95dc8bec7a00",
   "metadata": {},
   "source": [
    "Ce code fonctionne avec ces versions de bibliotheques :\n",
    "PyTorch version: 2.5.1+cpu\n",
    "CUDA available: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bba523f-4861-4e71-9f36-fe49f55be022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv(\"MetroPT3_imputed_final.csv\", delimiter=\",\", decimal=\".\", index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122f091b-0b02-48e1-b50d-0498cb43d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la colonne 'timestamp' en type datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce3e8f2-dbbb-4b4c-b008-be0e8c9259f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les colonnes continues et catégoriques pour l'entrainement\n",
    "continuous_features = [\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"]\n",
    "categorical_features = [\"COMP\", \"DV_eletric\", \"Towers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d2401b0-e72e-43e1-b611-c48e1debf4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes catégoriques en type \"category\"\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b119b2d8-4fb4-4866-b96f-244039a4cdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TP2</th>\n",
       "      <th>DV_pressure</th>\n",
       "      <th>Oil_temperature</th>\n",
       "      <th>Motor_current</th>\n",
       "      <th>Reservoirs</th>\n",
       "      <th>panne</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DV_eletric</th>\n",
       "      <th>Towers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.358</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 00:00:10</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.675</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.348</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01 00:00:20</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>9.338</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01 00:00:30</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.425</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.328</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01 00:00:40</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.475</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.318</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    TP2  DV_pressure  Oil_temperature  Motor_current  \\\n",
       "0 2020-02-01 00:00:00 -0.012       -0.024           53.600         0.0400   \n",
       "1 2020-02-01 00:00:10 -0.014       -0.022           53.675         0.0400   \n",
       "2 2020-02-01 00:00:20 -0.012       -0.022           53.600         0.0425   \n",
       "3 2020-02-01 00:00:30 -0.012       -0.022           53.425         0.0400   \n",
       "4 2020-02-01 00:00:40 -0.012       -0.022           53.475         0.0400   \n",
       "\n",
       "   Reservoirs  panne COMP DV_eletric Towers  \n",
       "0       9.358      0  1.0        0.0    1.0  \n",
       "1       9.348      0  1.0        0.0    1.0  \n",
       "2       9.338      0  1.0        0.0    1.0  \n",
       "3       9.328      0  1.0        0.0    1.0  \n",
       "4       9.318      0  1.0        0.0    1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Liste des colonnes nécessaires\n",
    "columns_to_keep = [\"timestamp\"] + continuous_features + [\"panne\"] + categorical_features\n",
    "\n",
    "# Réduire le DataFrame\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedfd480-5afd-437a-ac88-b2f66e414727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la colonne 'time_idx' basée sur les timestamps\n",
    "df['time_idx'] = ((df['timestamp'] - df['timestamp'].min()).dt.total_seconds() // 10).astype(int)\n",
    "\n",
    "# Ajouter une colonne 'group_id' pour identifier les groupes (utile pour un seul groupe)\n",
    "df['group_id'] = \"compresseur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb4a027a-c998-463a-a610-1d1acae1afc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TP2</th>\n",
       "      <th>DV_pressure</th>\n",
       "      <th>Oil_temperature</th>\n",
       "      <th>Motor_current</th>\n",
       "      <th>Reservoirs</th>\n",
       "      <th>panne</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DV_eletric</th>\n",
       "      <th>Towers</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.358</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>compresseur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 00:00:10</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.675</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.348</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>compresseur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01 00:00:20</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.600</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>9.338</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>compresseur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01 00:00:30</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.425</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.328</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>compresseur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01 00:00:40</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>53.475</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>9.318</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>compresseur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    TP2  DV_pressure  Oil_temperature  Motor_current  \\\n",
       "0 2020-02-01 00:00:00 -0.012       -0.024           53.600         0.0400   \n",
       "1 2020-02-01 00:00:10 -0.014       -0.022           53.675         0.0400   \n",
       "2 2020-02-01 00:00:20 -0.012       -0.022           53.600         0.0425   \n",
       "3 2020-02-01 00:00:30 -0.012       -0.022           53.425         0.0400   \n",
       "4 2020-02-01 00:00:40 -0.012       -0.022           53.475         0.0400   \n",
       "\n",
       "   Reservoirs  panne COMP DV_eletric Towers  time_idx     group_id  \n",
       "0       9.358      0  1.0        0.0    1.0         0  compresseur  \n",
       "1       9.348      0  1.0        0.0    1.0         1  compresseur  \n",
       "2       9.338      0  1.0        0.0    1.0         2  compresseur  \n",
       "3       9.328      0  1.0        0.0    1.0         3  compresseur  \n",
       "4       9.318      0  1.0        0.0    1.0         4  compresseur  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de020455-478f-43ea-9601-1c6e28f70dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "train_data = df[(df['timestamp'] >= '2020-02-01 00:00:00') & (df['timestamp'] <= '2020-06-07 14:30:00')]\n",
    "val_data   = df[(df['timestamp'] >= '2020-06-07 14:30:10') & (df['timestamp'] <= '2020-09-01 03:59:50')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3880c74-b59c-4e26-9c78-82e4e7f1c015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement : 1102501 lignes\n",
      "Validation : 739259 lignes\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les tailles des ensembles\n",
    "print(f\"Entraînement : {len(train_data)} lignes\")\n",
    "print(f\"Validation : {len(val_data)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211b6ac7-e78d-4080-9670-62d8aa8e2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_features:\n",
    "    train_data.loc[:, col] = train_data[col].astype(float).astype(int).astype(str).astype('category')\n",
    "    val_data.loc[:, col] = val_data[col].astype(float).astype(int).astype(str).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f192888c-5d14-47c9-a4a8-ff1d06bfa9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp          datetime64[ns]\n",
      "TP2                       float64\n",
      "DV_pressure               float64\n",
      "Oil_temperature           float64\n",
      "Motor_current             float64\n",
      "Reservoirs                float64\n",
      "panne                       int64\n",
      "COMP                     category\n",
      "DV_eletric               category\n",
      "Towers                   category\n",
      "time_idx                    int64\n",
      "group_id                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les types des colonnes\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c95b2a-5819-4556-b1af-2dd50a6617f0",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>#########################  Préparation des données pour le modèle ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "077d089d-ef96-4ac0-acc1-e84f416da48b",
   "metadata": {},
   "source": [
    "Création de datasets de type TimeSeriesDataSet, spécialement conçus pour les séries temporelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64097b21-3388-43f0-8ea4-86d6a21b8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les longueurs des séquences\n",
    "\n",
    "# Créer le dataset d'entraînement\n",
    "training = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"panne\",  # Cible définie comme 'panne'\n",
    "    group_ids=[\"group_id\"],\n",
    "    min_encoder_length=90,  # Ajuster selon votre besoin\n",
    "    max_encoder_length=180,\n",
    "    max_prediction_length=1,\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_reals=[\"TP2\", \"DV_pressure\", \"Oil_temperature\", \"Motor_current\", \"Reservoirs\"],\n",
    "    time_varying_unknown_categoricals=[\"COMP\", \"DV_eletric\", \"Towers\"],\n",
    ")\n",
    "\n",
    "# Créer le dataset de validation\n",
    "validation = TimeSeriesDataSet.from_dataset(training, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c52fdf4b-da85-434a-9e48-28b4ea23de4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes uniques dans le jeu de données d'entraînement : [0 2 1]\n",
      "Classes uniques dans le jeu de données de validation : [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Vérifiez les classes dans le jeu de données d'entraînement et de validation\n",
    "print(\"Classes uniques dans le jeu de données d'entraînement :\", train_data[\"panne\"].unique())\n",
    "print(\"Classes uniques dans le jeu de données de validation :\", val_data[\"panne\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5808ae1e-2017-4d55-a2ae-630254f2ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le dataset de validation\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training,\n",
    "    val_data,  # Données de validation\n",
    "    stop_randomization=True  # Pour garantir que les séquences sont cohérentes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201a55c-ab8f-45f8-89d8-8d6558f13d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les prédictions\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=64)\n",
    "\n",
    "# Récupérer les prédictions et les cibles\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "tft.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        x, y = batch\n",
    "        if isinstance(y, tuple):\n",
    "            y = y[0]\n",
    "\n",
    "        y_hat = tft(x)[\"prediction\"]\n",
    "        preds = torch.argmax(y_hat, dim=-1).cpu().numpy()\n",
    "        targets = y.cpu().numpy()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(targets)\n",
    "\n",
    "# Convertir en tableaux numpy\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "# Afficher les métriques\n",
    "print(\"Rapport de classification par classe :\")\n",
    "print(classification_report(all_targets, all_preds))\n",
    "\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(all_targets, all_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138cc9b1-0e4a-4a81-950e-4031cd9227dc",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>######################### Charger les DataLoaders ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b36335ed-bfa1-4167-8fb5-1eaa3c428d19",
   "metadata": {},
   "source": [
    "Les DataLoaders permettent de charger les données par lots (batches) lors de l'entraînement et de la validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d0cba9-43ac-41e0-9784-991dd5543b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les DataLoaders pour l'entraînement et la validation\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=64, num_workers=4, batch_sampler=None)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=64, num_workers=4, batch_sampler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b512d-15da-4aec-afb5-f6d49b467282",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>######################### Initialiser le modèle TFT ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8031aa0-4797-492d-a623-bdc7e8498b8e",
   "metadata": {},
   "source": [
    "Configurez et initialisez le modèle avec les paramètres appropriés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2462fae1-7fb2-4d87-9a75-51a9cfb840f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:171: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le modèle TFT\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,     # Taux d'apprentissage pour l'optimisation\n",
    "    hidden_size=16,         # Taille des couches cachées\n",
    "    attention_head_size=4,  # Nombre de têtes d'attention\n",
    "    dropout=0.1,            # Pour éviter le surapprentissage\n",
    "    hidden_continuous_size=8,  # Taille des représentations continues\n",
    "    loss=QuantileLoss(),       # Fonction de perte pour les séries temporelles\n",
    "    log_interval=10,           # Journaliser toutes les 10 itérations\n",
    "    reduce_on_plateau_patience=4,  # Réduire le learning rate si stagnation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1626adb7-ee1b-407a-9c5c-429ae71440af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulation dans LightningModule\n",
    "class CustomTFT(LightningModule):\n",
    "    def __init__(self, tft_model):\n",
    "        super().__init__()\n",
    "        self.tft_model = tft_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tft_model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        if isinstance(y, tuple):\n",
    "            y = y[0]\n",
    "        y_hat = self.tft_model(x)\n",
    "        predictions = y_hat[\"prediction\"]\n",
    "        loss = self.tft_model.loss(predictions, y)\n",
    "        self.log(\"train_loss\", loss, batch_size=y.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        if isinstance(y, tuple):\n",
    "            y = y[0]\n",
    "        y_hat = self.tft_model(x)\n",
    "        predictions = y_hat[\"prediction\"]\n",
    "        val_loss = self.tft_model.loss(predictions, y)\n",
    "        self.log(\"val_loss\", val_loss, batch_size=y.size(0))\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.03)\n",
    "\n",
    "\n",
    "# Créer un modèle encapsulé\n",
    "model = CustomTFT(tft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e0185-e7a1-47df-8293-d81908dd9be2",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>######################### Entraîner le modèle ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bec5042-451d-4f40-8c7a-f66dc2096f31",
   "metadata": {},
   "source": [
    "Utilisation de PyTorch Lightning pour entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db9a00e6-4f27-4b53-80ad-cff28903ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | tft_model | TemporalFusionTransformer | 19.1 K\n",
      "--------------------------------------------------------\n",
      "19.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.1 K    Total params\n",
      "0.077     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2241abf9a0e46ecbd463b5546a5c9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e121b818bf794bec9367afe04c573c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ecb40f8a4c4f6e8bf7aece11143d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dc0ac3c2374bb89e0ff3d9e19e6542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Ajouter les callbacks pour Early Stopping et sauvegarde du modèle\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Surveiller la métrique val_loss\n",
    "    patience=5,          # Arrêter après 5 époques sans amélioration\n",
    "    verbose=True,\n",
    "    mode=\"min\"           # Minimiser la perte\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",  # Sauvegarder le meilleur modèle basé sur val_loss\n",
    "    dirpath=\"checkpoints\",  # Dossier pour les checkpoints\n",
    "    filename=\"best-checkpoint\",  # Nom du fichier de checkpoint\n",
    "    save_top_k=1,               # Sauvegarder uniquement le meilleur modèle\n",
    "    mode=\"min\"                  # Minimiser la perte\n",
    ")\n",
    "\n",
    "\n",
    "# Configurer le Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,                # Nombre d'époques maximum\n",
    "    accelerator=\"cpu\",           # Utilisation du CPU\n",
    "    gradient_clip_val=0.1,       # Clip pour éviter les gradients explosifs\n",
    "    callbacks=[early_stopping, checkpoint_callback],  # Ajouter les callbacks\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "# Vérifier si l'entraînement a été interrompu et sauvegarder l'état\n",
    "trainer.save_checkpoint(\"last-phase-checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dfd709-9471-4b20-b29f-109c15644c92",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>######################### Reprendre l'entraînement ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880310bf-8ef4-449e-b90f-70e1c30ce1b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Charger le modèle depuis le dernier checkpoint\n",
    "checkpoint_path = \"last-phase-checkpoint.ckpt\"\n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "# Configurer Early Stopping et Checkpoint Callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Configurer le Trainer pour reprendre l'entraînement\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,               # Le nombre total d'époques à effectuer\n",
    "    accelerator=\"cpu\",\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    resume_from_checkpoint=checkpoint_path  # Reprendre depuis le dernier checkpoint\n",
    ")\n",
    "\n",
    "# Continuer l'entraînement\n",
    "trainer.fit(model=tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4eb4c-943a-4436-a6b1-dc061d8c4086",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>######################### Faire des prédictions ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07e853-3608-40ff-a7f5-a4c3ebf3dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\TFT\\env_tft\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\TFT\\env_tft\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédictions\n",
    "raw_predictions, x = tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "# Afficher les prédictions brutes\n",
    "print(raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bbc51-29ef-4327-aaf2-35aba33eec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les prédictions\n",
    "predictions = tft.predict(val_dataloader)\n",
    "\n",
    "# Afficher les dimensions des prédictions\n",
    "print(f\"Shape of predictions: {predictions.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2c648-99ad-42c6-bcac-299328634303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher quelques exemples de prédictions\n",
    "print(\"Example predictions:\", predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d035126-1ebe-42de-8dc1-7f68ca8e4c69",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>######################### Évaluation ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc17dcf2-3886-4e2f-b427-3e7e99b4935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure perte de validation (val_loss): 0.5704852342605591\n"
     ]
    }
   ],
   "source": [
    "# Les métriques de validation sont enregistrées par le Trainer\n",
    "print(f\"Meilleure perte de validation (val_loss): {trainer.callback_metrics['val_loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d101fbe-a1b4-45af-b6f8-1859ae017376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:107: UserWarning: Not all dimensions are equal for tensors shapes. Example tensor torch.Size([64, 1, 4, 180]). Returning list instead of torch.Tensor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Prediction should only have one extra dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Calculer les métriques\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m smape \u001b[38;5;241m=\u001b[39m \u001b[43mSMAPE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactuals\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     21\u001b[0m mae \u001b[38;5;241m=\u001b[39m MAE()(predictions, actuals)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     22\u001b[0m rmse \u001b[38;5;241m=\u001b[39m RMSE()(predictions, actuals)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\torchmetrics\\metric.py:316\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\torchmetrics\\metric.py:385\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\torchmetrics\\metric.py:550\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    552\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\pytorch_forecasting\\metrics\\base_metrics.py:798\u001b[0m, in \u001b[0;36mMultiHorizonMetric.update\u001b[1;34m(self, y_pred, target)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    796\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((target\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),), fill_value\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 798\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# weight samples\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\pytorch_forecasting\\metrics\\point.py:69\u001b[0m, in \u001b[0;36mSMAPE.loss\u001b[1;34m(self, y_pred, target)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_pred, target):\n\u001b[1;32m---> 69\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (y_pred \u001b[38;5;241m-\u001b[39m target)\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m/\u001b[39m (y_pred\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m+\u001b[39m target\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\pytorch_forecasting\\metrics\\base_metrics.py:93\u001b[0m, in \u001b[0;36mMetric.to_prediction\u001b[1;34m(self, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantiles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction should only have one extra dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: Prediction should only have one extra dimension"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.metrics import SMAPE, MAE, RMSE\n",
    "import torch\n",
    "\n",
    "# Faire des prédictions\n",
    "actuals = []\n",
    "for batch in val_dataloader:\n",
    "    x, y = batch\n",
    "    if isinstance(y, tuple):  # Si `y` est un tuple, prendre la première valeur\n",
    "        y = y[0]\n",
    "    actuals.append(y)\n",
    "\n",
    "# Concaténer les valeurs réelles en un seul tenseur\n",
    "actuals = torch.cat(actuals)\n",
    "\n",
    "# Obtenir les prédictions du modèle\n",
    "predictions = tft.predict(val_dataloader, mode=\"raw\")\n",
    "predictions = predictions[\"prediction\"]\n",
    "\n",
    "# Calculer les métriques\n",
    "smape = SMAPE()(predictions, actuals).item()\n",
    "mae = MAE()(predictions, actuals).item()\n",
    "rmse = RMSE()(predictions, actuals).item()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"SMAPE: {smape:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72c37e7b-e844-411b-a7a6-77be0d3b03b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification par classe :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\usermine\\Amine-Jupiter\\SESSION6\\tft\\env_tft\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00  737458.0\n",
      "           1       0.00      0.00      0.00    1621.0\n",
      "           2       0.00      0.00      0.00     180.0\n",
      "           5       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00  739259.0\n",
      "   macro avg       0.00      0.00      0.00  739259.0\n",
      "weighted avg       0.00      0.00      0.00  739259.0\n",
      "\n",
      "Matrice de confusion :\n",
      "[[     0      0      0 684156  53302]\n",
      " [     0      0      0   1621      0]\n",
      " [     0      0      0    180      0]\n",
      " [     0      0      0      0      0]\n",
      " [     0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Supposons que `tft` est votre modèle déjà chargé\n",
    "# Préparez votre DataLoader pour la validation\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=64)\n",
    "\n",
    "# Obtenir les prédictions\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "tft.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        x, y = batch\n",
    "\n",
    "        # Si y est un tuple, extraire la cible réelle\n",
    "        if isinstance(y, tuple):\n",
    "            y = y[0]\n",
    "\n",
    "        # Obtenez les prédictions\n",
    "        y_hat = tft(x)[\"prediction\"]\n",
    "\n",
    "        # Convertir les prédictions en classe la plus probable\n",
    "        preds = torch.argmax(y_hat, dim=-1).cpu().numpy()\n",
    "        targets = y.cpu().numpy()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(targets)\n",
    "\n",
    "# Convertir les listes en tableaux numpy\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "# Calcul des métriques par classe\n",
    "print(\"Rapport de classification par classe :\")\n",
    "print(classification_report(all_targets, all_preds))\n",
    "\n",
    "# Matrice de confusion\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(all_targets, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b94fa4ec-a67a-441a-9c6f-84beee2cb7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catégories définies : ['COMP', 'DV_eletric', 'Towers']\n",
      "Reels définis : ['encoder_length', 'time_idx', 'TP2', 'DV_pressure', 'Oil_temperature', 'Motor_current', 'Reservoirs']\n"
     ]
    }
   ],
   "source": [
    "print(\"Catégories définies :\", validation.categoricals)\n",
    "print(\"Reels définis :\", validation.reals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "600e67ea-a5c4-4490-b6d5-1885d7965311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes uniques dans la colonne 'panne' :\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'panne'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Vérifier les classes uniques dans la colonne cible\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses uniques dans la colonne \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpanne\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpanne\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[1;31mKeyError\u001b[0m: 'panne'"
     ]
    }
   ],
   "source": [
    "# Vérifier les classes uniques dans la colonne cible\n",
    "print(\"Classes uniques dans la colonne 'panne' :\")\n",
    "print(validation.data[\"panne\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad5df0-ca04-49e9-a6b8-ed229003aa51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41be4d-e9a3-4a1c-8860-c623af84ebb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381d057-426a-4587-9474-b67ee5ed2c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d7de90a-d131-4197-ba91-6f3a8bcee5cb",
   "metadata": {},
   "source": [
    "<ul style=\"text-align: center;font-family: times, serif; font-size:14pt; color:Red;\">\n",
    "<strong>######################### Sauvegarder le modèle ############################</strong>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fb1f083-ff5c-43ba-9c88-34be000ffe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé sous : tft_model_1_2025_01_02_08_20_epoch2.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le modèle\n",
    "model_checkpoint = \"tft_model_1_2025_01_02_08_20_epoch2.ckpt\"\n",
    "trainer.save_checkpoint(model_checkpoint)\n",
    "print(f\"Modèle sauvegardé sous : {model_checkpoint}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e97c5747-a2af-4a26-89eb-351dc7288729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids du modèle sauvegardés avec succès !\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sauvegarder uniquement les poids du modèle\n",
    "torch.save(tft.state_dict(), \"tft_model_weights_2025_01_02_08_20_epoch2.pth\")\n",
    "print(\"Poids du modèle sauvegardés avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3de62-58f0-430a-973e-9f4743c7dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "# Charger ou initialiser votre modèle TFT\n",
    "tft = TemporalFusionTransformer(...)  # Assurez-vous que le modèle est déjà entraîné\n",
    "\n",
    "# Sauvegarder le modèle en fichier `.pkl`\n",
    "with open(\"tft_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tft, f)\n",
    "\n",
    "print(\"Modèle sauvegardé en 'tft_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cacecb-2d6d-4401-ad61-afc108644186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "# Charger le modèle depuis le checkpoint\n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(\"tft_model_final.ckpt\")\n",
    "print(\"Modèle chargé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae848426-f778-47b0-b6be-5519d9b83256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721857da-c1ba-40d5-8bdf-8e2164324b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c149fa6-29b7-4159-89b5-347f9bb63fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
